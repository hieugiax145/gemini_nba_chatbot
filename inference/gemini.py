from google import genai
from google.genai.types import Tool,GenerateContentConfig, GoogleSearch
# Potentially keep these if needed for specific filtering or pre-defined answers
# from data.text_data import unsure, non_nba 
# from modules.analysis import isNBA # You might not need isNBA if Gemini handles context

# --- It's highly recommended to load API keys securely, e.g., from environment variables ---
# Example: Load from environment variable
# GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY') 
# Or uncomment and paste directly (less secure for production)
# GOOGLE_API_KEY = "YOUR_API_KEY" 

# Configure the Gemini client library
# try:
#     # Securely configure the API key (best practice)
GOOGLE_API_KEY = 'AIzaSyBSbxCDL6j8UJobJJN8ghAlR1ReQSW_FdE'
#     if not GOOGLE_API_KEY:
#         raise ValueError("GOOGLE_API_KEY environment variable not set.")
#     genai.configure(api_key=GOOGLE_API_KEY)
# except Exception as e:
#     print(f"Error configuring Gemini API: {e}")
#     # Handle the error appropriately - maybe disable Gemini features

client = genai.Client(api_key=GOOGLE_API_KEY)
model_id = "gemini-2.0-flash"

class InferenceNetwork(object):
    """
    A class to facilitate query inference using the Google Gemini API.

    This class takes a user query, sends it to the Gemini API, 
    and returns the generated response.
    """

    def __init__(self, query):
        """
        Initializes the InferenceNetwork with the user query.

        Args:
            query (str): The query or question passed in by the user.
        """
        self.query = query
        # Initialize the Gemini model (e.g., 'gemini-pro' or 'gemini-1.5-flash')
        # Choose the model that best suits your needs and budget
        try:
            self.model = client.models
        except Exception as e:
            print(f"Error initializing Gemini model: {e}")
            self.model = None # Mark model as unusable
        self.search_tool = Tool(
            google_search=GoogleSearch()
            # Use an empty dictionary {} if the above causes import/version issues,
            # as newer library versions sometimes simplify this:
            # Google Search_retrieval={}
         )

        # --- Remove old classifier loading ---
        # model_file = "inference/models/classifiers/query_classifier.pkl"
        # query_clf = joblib.load(model_file)
        # self.final=query_clf

    def response(self):
        """
        Generates and returns a response using the Gemini API, potentially
        leveraging Google Search for current information.

        Returns:
            str: The response generated by the Gemini model, or an error message.
        """
        if not self.model:
            return "Sorry, I cannot process your request at this time due to an internal configuration issue."

        # --- Construct the prompt for Gemini ---
        # Keep the persona instructions. The model decides when to use Search.
        prompt = f"""You are a helpful assistant specializing in NBA (National Basketball Association) information.
Your knowledge includes players, teams, stats, history, rules, and recent events related to the NBA.
Use your internal knowledge and search the web if necessary for the most current information to answer accurately.
Please answer the following question:

Question: "{self.query}"

Answer:"""

        try:
            # --- Call the Gemini API with the Search tool enabled ---
            gemini_response = client.models.generate_content(
                model=model_id,
                contents=prompt,
                config=GenerateContentConfig(
                    response_modalities=["TEXT"],
                    tools=[self.search_tool]
                )
                 # Pass the configured tool
            )
            print(gemini_response)
            for each in gemini_response.candidates[0].content.parts:
                    print(each.text)
            return gemini_response.candidates[0].content.parts[0].text
# Example response:
# The next total solar eclipse visible in the contiguous United States will be on ...

# To get grounding metadata as web content.
            # print(gemini_response.candidates[0].grounding_metadata.search_entry_point.rendered_content)

            # --- Extract and return the text response ---
            if gemini_response.prompt_feedback.block_reason:
                block_reason = gemini_response.prompt_feedback.block_reason
                print(f"Prompt blocked due to: {block_reason}")
                return f"Sorry, I cannot respond to that query due to content restrictions ({block_reason})."

            if gemini_response.parts:
                 # Check if the search tool was actually invoked (optional logging/debugging)
                try:
                    if gemini_response.function_calls: # Search is treated like a function call
                         print("Note: Google Search tool was likely used for this response.")
                         # You could potentially inspect gemini_response.function_calls further
                except AttributeError:
                    pass # Older versions might not have function_calls attribute easily accessible here
                return gemini_response.text
            else:
                print("Gemini returned an empty response without a block reason.")
                return "Sorry, I received an unexpected empty response."

        except Exception as e:
            print(f"ERROR: An error occurred while calling the Gemini API: {e}")
            # logging.exception(f"Gemini API call failed. Query: {self.query}") # Optional
            return f"Sorry, I encountered an error trying to answer your question. Please try again later."
